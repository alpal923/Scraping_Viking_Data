{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from googletrans import Translator\n",
    "from collections import defaultdict\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize a list to store the data for each individual page\n",
    "all_data = {}\n",
    "\n",
    "# Initialize the web driver\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "# Initial search page URL\n",
    "url = \"https://samlingar.shm.se/sok?type=object&productionPeriod=Vikingatid&hasImage=1&category=Arkeologisk%20samling&category=Vapen%20och%20rustningar&listType=archaeological&rows=500&offset=0\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load (you may need to adjust the sleep duration)\n",
    "time.sleep(2)\n",
    "\n",
    "# Find the cookie disclaimer button by its aria-label\n",
    "cookie_disclaimer = driver.find_element(By.CSS_SELECTOR, '[aria-label=\"Godkänn alla kakor\"]')\n",
    "# Check if the cookie disclaimer button is displayed and then click it\n",
    "if cookie_disclaimer.is_displayed():\n",
    "    ActionChains(driver).move_to_element(cookie_disclaimer).click().perform()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data from the main table\n",
    "table = driver.find_element(By.TAG_NAME, \"table\")\n",
    "df = pd.read_html(table.get_attribute('outerHTML'))[0]\n",
    "\n",
    "# Drop the 'Bild' column\n",
    "if 'Bild' in df.columns:\n",
    "    df.drop(columns=['Bild'], inplace=True)\n",
    "\n",
    "# Extract museum names from the 'title' attribute of each <i> element\n",
    "museum_elements = driver.find_elements(By.CSS_SELECTOR, \"td i.museum-icon\")\n",
    "museum_names = [elem.get_attribute('title') for elem in museum_elements]\n",
    "\n",
    "# Replace the 'Museum' column with extracted text\n",
    "if 'Museum' in df.columns and len(museum_names) == len(df):\n",
    "    df['Museum'] = museum_names\n",
    "else:\n",
    "    print(\"Mismatch in number of rows while extracting museum names\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect names and href links for each item\n",
    "item_link = [(item.get_attribute('href')) for item in driver.find_elements(By.CLASS_NAME, \"archaeological-list__link\")]\n",
    "\n",
    "item_names = [f\"{item.text} - {index+1}\" for index, item in enumerate(driver.find_elements(By.CLASS_NAME, \"archaeological-list__link\"))]\n",
    "df['Unique Name'] = item_names\n",
    "df['Catalog Link'] = item_link\n",
    "\n",
    "# Initialize a column for extra details\n",
    "df['Extra Details'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to each item's link and scrape additional details\n",
    "for index, link in enumerate(df['Catalog Link']):\n",
    "    driver.get(link)\n",
    "\n",
    "    # Scrape the details from the item's page\n",
    "    item_details = {}\n",
    "    item_tables = driver.find_elements(By.TAG_NAME, \"table\")\n",
    "    for item_table in item_tables:\n",
    "        item_df = pd.read_html(item_table.get_attribute('outerHTML'))[0]\n",
    "        for row in item_df.itertuples(index=False):\n",
    "            item_details[row[0]] = row[1]\n",
    "\n",
    "    # Store the scraped details as JSON in the DataFrame\n",
    "    df.at[index, 'Extra Details'] = json.dumps(item_details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Föremålsbenämning</th>\n",
       "      <th>Föremålsnr.</th>\n",
       "      <th>Förvärvsnr.</th>\n",
       "      <th>Andra nummer</th>\n",
       "      <th>Material</th>\n",
       "      <th>Plats</th>\n",
       "      <th>Fornlämning</th>\n",
       "      <th>Socken</th>\n",
       "      <th>Landskap</th>\n",
       "      <th>Land</th>\n",
       "      <th>Kontexttyp</th>\n",
       "      <th>Kontextnr.</th>\n",
       "      <th>Artbedömning</th>\n",
       "      <th>Benslagsbedömning</th>\n",
       "      <th>Museum</th>\n",
       "      <th>Unique Name</th>\n",
       "      <th>Catalog Link</th>\n",
       "      <th>Extra Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rundsköld</td>\n",
       "      <td>107823_HST</td>\n",
       "      <td>34000</td>\n",
       "      <td>Undernummer: Bj 750</td>\n",
       "      <td>Järn</td>\n",
       "      <td>Björkö, Hemlanden</td>\n",
       "      <td>L2017:1904</td>\n",
       "      <td>Adelsö socken</td>\n",
       "      <td>Uppland</td>\n",
       "      <td>Sverige</td>\n",
       "      <td>Kammargrav</td>\n",
       "      <td>750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Historiska museet</td>\n",
       "      <td>Rundsköld - 1</td>\n",
       "      <td>https://samlingar.shm.se/object/1D1DB077-E65D-...</td>\n",
       "      <td>{\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yxa Petersen F</td>\n",
       "      <td>107824_HST</td>\n",
       "      <td>34000</td>\n",
       "      <td>Undernummer: Bj 750</td>\n",
       "      <td>Järn</td>\n",
       "      <td>Björkö, Hemlanden</td>\n",
       "      <td>L2017:1904</td>\n",
       "      <td>Adelsö socken</td>\n",
       "      <td>Uppland</td>\n",
       "      <td>Sverige</td>\n",
       "      <td>Kammargrav</td>\n",
       "      <td>750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Historiska museet</td>\n",
       "      <td>Yxa Petersen F - 2</td>\n",
       "      <td>https://samlingar.shm.se/object/F2BCA591-02C2-...</td>\n",
       "      <td>{\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svärdsskida</td>\n",
       "      <td>107825_HST</td>\n",
       "      <td>34000</td>\n",
       "      <td>Undernummer: Bj 750</td>\n",
       "      <td>Cu-legering, Trä</td>\n",
       "      <td>Björkö, Hemlanden</td>\n",
       "      <td>L2017:1904</td>\n",
       "      <td>Adelsö socken</td>\n",
       "      <td>Uppland</td>\n",
       "      <td>Sverige</td>\n",
       "      <td>Kammargrav</td>\n",
       "      <td>750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Historiska museet</td>\n",
       "      <td>svärdsskida - 3</td>\n",
       "      <td>https://samlingar.shm.se/object/C1A0693F-6439-...</td>\n",
       "      <td>{\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tveeggat svärd</td>\n",
       "      <td>107827_HST</td>\n",
       "      <td>34000</td>\n",
       "      <td>Undernummer: Bj 750</td>\n",
       "      <td>Järn</td>\n",
       "      <td>Björkö, Hemlanden</td>\n",
       "      <td>L2017:1904</td>\n",
       "      <td>Adelsö socken</td>\n",
       "      <td>Uppland</td>\n",
       "      <td>Sverige</td>\n",
       "      <td>Kammargrav</td>\n",
       "      <td>750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Historiska museet</td>\n",
       "      <td>Tveeggat svärd - 4</td>\n",
       "      <td>https://samlingar.shm.se/object/A38BC834-6E7D-...</td>\n",
       "      <td>{\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tveeggat svärd</td>\n",
       "      <td>107077_HST</td>\n",
       "      <td>33136</td>\n",
       "      <td>FID: 107077</td>\n",
       "      <td>Järn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Okänt landskap</td>\n",
       "      <td>Sverige</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Historiska museet</td>\n",
       "      <td>Tveeggat svärd - 5</td>\n",
       "      <td>https://samlingar.shm.se/object/CE5A5104-17C2-...</td>\n",
       "      <td>{\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Föremålsbenämning Föremålsnr. Förvärvsnr.         Andra nummer  \\\n",
       "0         Rundsköld  107823_HST       34000  Undernummer: Bj 750   \n",
       "1    Yxa Petersen F  107824_HST       34000  Undernummer: Bj 750   \n",
       "2       svärdsskida  107825_HST       34000  Undernummer: Bj 750   \n",
       "3    Tveeggat svärd  107827_HST       34000  Undernummer: Bj 750   \n",
       "4    Tveeggat svärd  107077_HST       33136          FID: 107077   \n",
       "\n",
       "           Material              Plats Fornlämning         Socken  \\\n",
       "0              Järn  Björkö, Hemlanden  L2017:1904  Adelsö socken   \n",
       "1              Järn  Björkö, Hemlanden  L2017:1904  Adelsö socken   \n",
       "2  Cu-legering, Trä  Björkö, Hemlanden  L2017:1904  Adelsö socken   \n",
       "3              Järn  Björkö, Hemlanden  L2017:1904  Adelsö socken   \n",
       "4              Järn                NaN         NaN            NaN   \n",
       "\n",
       "         Landskap     Land  Kontexttyp Kontextnr.  Artbedömning  \\\n",
       "0         Uppland  Sverige  Kammargrav        750           NaN   \n",
       "1         Uppland  Sverige  Kammargrav        750           NaN   \n",
       "2         Uppland  Sverige  Kammargrav        750           NaN   \n",
       "3         Uppland  Sverige  Kammargrav        750           NaN   \n",
       "4  Okänt landskap  Sverige         NaN        NaN           NaN   \n",
       "\n",
       "   Benslagsbedömning             Museum         Unique Name  \\\n",
       "0                NaN  Historiska museet       Rundsköld - 1   \n",
       "1                NaN  Historiska museet  Yxa Petersen F - 2   \n",
       "2                NaN  Historiska museet     svärdsskida - 3   \n",
       "3                NaN  Historiska museet  Tveeggat svärd - 4   \n",
       "4                NaN  Historiska museet  Tveeggat svärd - 5   \n",
       "\n",
       "                                        Catalog Link  \\\n",
       "0  https://samlingar.shm.se/object/1D1DB077-E65D-...   \n",
       "1  https://samlingar.shm.se/object/F2BCA591-02C2-...   \n",
       "2  https://samlingar.shm.se/object/C1A0693F-6439-...   \n",
       "3  https://samlingar.shm.se/object/A38BC834-6E7D-...   \n",
       "4  https://samlingar.shm.se/object/CE5A5104-17C2-...   \n",
       "\n",
       "                                       Extra Details  \n",
       "0  {\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...  \n",
       "1  {\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...  \n",
       "2  {\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...  \n",
       "3  {\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...  \n",
       "4  {\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Close the driver\n",
    "driver.quit()\n",
    "\n",
    "# Replace '-' with NaNs in the entire DataFrame\n",
    "df.replace('-', np.NaN, inplace=True)\n",
    "\n",
    "df.head()  # Display the first few rows of the table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are my own functions that help clean the data\n",
    "\n",
    "def search_columns_for_substring(columns, substring):\n",
    "    return [col for col in columns if substring in col]\n",
    "\n",
    "# this function counts how many empty values are in each column for a data set (use this after the drop col function to verify)\n",
    "def count_nans_in_dataframe(df):\n",
    "    nan_counts = df.isna().sum()\n",
    "    return pd.DataFrame({'Column': nan_counts.index, 'NaN Count': nan_counts.values})\n",
    "\n",
    "# this function drops columns that do not meet the minimum threshold\n",
    "# if by=\"count\" then drop columns that don't have at least that many populated fields\n",
    "    # ie. by_val=100 drops columns that have less than 100 populated rows\n",
    "# if by=\"prop\" then drop columns that don't have at least by_val% populated rows\n",
    "    # ie. by_val=0.05 drops columns that aren't at least 5% populated\n",
    "# if by=\"field\" then drop columns that have more missing values than the columns specified\n",
    "    # ie. by_val=\"Last_Device_Array.anv\" will keep Last_Device_Array.anv but drop any cols that have more missing values than Last_Device_Array.anv\n",
    "def drop_columns_with_fewer_nans(df, by=\"prop\", by_val=\"0.05\"):\n",
    "    if by == \"count\":\n",
    "        threshold = float(by_val)\n",
    "    elif by == \"prop\": threshold = round(df.shape[0]*float(by_val))\n",
    "    elif by == \"field\": threshold = df.shape[0]-df[by_val].isna().sum()\n",
    "    cols_to_drop = []\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().sum() > df.shape[0]-threshold:\n",
    "            cols_to_drop.append(col)\n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "    return df\n",
    "\n",
    "# this function to drops columns with duplicate names\n",
    "def drop_duplicate_columns(df):\n",
    "    duplicates = df.columns[df.columns.duplicated(keep='first')]\n",
    "    df = df.loc[:, ~df.columns.duplicated(keep='first')]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### UNPACK JSON\n",
    "# Load the dataset\n",
    "# dataset = pd.read_csv('/Users/aly.milne/Library/CloudStorage/OneDrive-BrighamYoungUniversity/Fall 2023/STAT 386/ST386_Final_Project/Scraped_Data/Viking_war_artifacts.csv')\n",
    "\n",
    "# unpack json\n",
    "df['Extra Details'] = df['Extra Details'].map(json.loads)\n",
    "war_artifacts_exploded = pd.json_normalize(df.to_dict(orient='records'))\n",
    "\n",
    "# drop rows that are not at least 25% populated\n",
    "cleaned_war_artifacts = drop_columns_with_fewer_nans(war_artifacts_exploded, \"prop\", 0.25)\n",
    "\n",
    "# Removing 'Extra Details.' prefix from column names\n",
    "cleaned_war_artifacts.columns = cleaned_war_artifacts.columns.str.replace('Extra Details.', '', regex=False)\n",
    "\n",
    "# Applying the function to your dataframe\n",
    "cleaned_war_artifacts = drop_duplicate_columns(cleaned_war_artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache for storing geocoded locations\n",
    "geocode_cache = {}\n",
    "\n",
    "def geocode(location):\n",
    "    \"\"\" Geocode a location using Nominatim API with caching. \"\"\"\n",
    "    # Check if the location is already in the cache\n",
    "    if location in geocode_cache:\n",
    "        return geocode_cache[location]\n",
    "\n",
    "    url = 'https://nominatim.openstreetmap.org/search'\n",
    "    headers = {\n",
    "        'User-Agent': 'alyanngirl@gmail.com'\n",
    "    }\n",
    "    params = {\n",
    "        'q': location,\n",
    "        'format': 'json'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        if results:\n",
    "            lat_lon = (results[0]['lat'], results[0]['lon'])\n",
    "            geocode_cache[location] = lat_lon  # Cache the result\n",
    "            return lat_lon\n",
    "\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def geocode_location(row):\n",
    "    location = row['Plats']\n",
    "    lat, lon = geocode(location)\n",
    "    time.sleep(0.5)\n",
    "    return pd.Series([lat, lon])\n",
    "\n",
    "# Apply geocode function to each row and create new columns for latitude and longitude\n",
    "cleaned_war_artifacts[['latitude', 'longitude']] = cleaned_war_artifacts.apply(geocode_location, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the updated DataFrame\n",
    "cleaned_war_artifacts.to_csv('war_w_locations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternates: \n",
    "# https://samlingar.shm.se/sok?type=object&productionPeriod=Vikingatid&hasImage=1&category=Arkeologisk%20samling&category=Vapen%20och%20rustningar&listType=archaeological&rows=500&offset=0\n",
    "# https://samlingar.shm.se/sok?type=object&productionPeriod=Vikingatid&hasImage=1&category=Arkeologisk%20samling&category=Handel%20och%20v%C3%A4rdem%C3%A4tare&listType=archaeological&rows=300&offset=0\n",
    "# https://samlingar.shm.se/sok?type=object&query=Vikingatid&listType=archaeological&rows=1000&offset=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the translator and cache\n",
    "translator = Translator()\n",
    "translations_cache = defaultdict(str)\n",
    "\n",
    "# Function to batch translate a list of texts\n",
    "def batch_translate(texts, src='sv', dest='en'):\n",
    "    # Filter out None values and ensure text is string\n",
    "    filtered_texts = [str(text) for text in texts if pd.notna(text)]\n",
    "    \n",
    "    # Batch processing and caching\n",
    "    batch_size = 10  # Adjust batch size as needed\n",
    "    for i in range(0, len(filtered_texts), batch_size):\n",
    "        batch = filtered_texts[i:i+batch_size]\n",
    "        untranslated_batch = [text for text in batch if text not in translations_cache]\n",
    "\n",
    "        if untranslated_batch:\n",
    "            try:\n",
    "                translations = translator.translate(untranslated_batch, src=src, dest=dest)\n",
    "                for text, translation in zip(untranslated_batch, translations):\n",
    "                    translations_cache[text] = translation.text\n",
    "            except Exception as e:  # General exception catch\n",
    "                print(f\"Error during translation: {e}\")\n",
    "                for text in untranslated_batch:\n",
    "                    translations_cache[text] = text\n",
    "\n",
    "        time.sleep(0.5)  # Respect rate limits\n",
    "\n",
    "    return [translations_cache[text] for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating column: Föremålsbenämning\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m# Ensure no None values are passed to batch_translate\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         column_values \u001b[38;5;241m=\u001b[39m df[column]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 15\u001b[0m         df[column \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_Translated\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_translate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m df_war_translate\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m, in \u001b[0;36mbatch_translate\u001b[0;34m(texts, src, dest)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m untranslated_batch:\n\u001b[1;32m     24\u001b[0m                 translations_cache[text] \u001b[38;5;241m=\u001b[39m text\n\u001b[0;32m---> 26\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Respect rate limits\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [translations_cache[text] \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "###### TRANSLATE\n",
    "# Load your datasets\n",
    "df_war_translate = cleaned_war_artifacts\n",
    "\n",
    "# Identify text columns in the dataframes\n",
    "text_columns_war = df_war_translate.select_dtypes(include=['object']).columns\n",
    "text_columns_war = [col for col in text_columns_war if col != 'Unique Name']\n",
    "\n",
    "# Translate text columns\n",
    "for df, text_columns in [(df_war_translate, text_columns_war)]:\n",
    "    for column in text_columns:\n",
    "        print(f\"Translating column: {column}\")\n",
    "        # Ensure no None values are passed to batch_translate\n",
    "        column_values = df[column].apply(lambda x: x if x is not None else '').tolist()\n",
    "        df[column + '_Translated'] = batch_translate(column_values)\n",
    "\n",
    "df_war_translate.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Use .loc to assign the values back to avoid SettingWithCopyWarning\u001b[39;00m\n\u001b[1;32m     14\u001b[0m cleaned_war_artifacts\u001b[38;5;241m.\u001b[39mloc[start:end\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, column \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_Translated\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m translated_texts\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###### TRANSLATE: WAR ARTIFACTS\n",
    "text_columns = cleaned_war_artifacts.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Translate each text column\n",
    "for column in text_columns:\n",
    "    # Process the DataFrame in chunks\n",
    "    chunk_size = 100  # Adjust based on your data and rate limits\n",
    "    for start in range(0, cleaned_war_artifacts.shape[0], chunk_size):\n",
    "        end = start + chunk_size\n",
    "        df_slice = cleaned_war_artifacts[start:end]\n",
    "        translated_texts = batch_translate(df_slice[column].astype(str).tolist())\n",
    "        \n",
    "        # Use .loc to assign the values back to avoid SettingWithCopyWarning\n",
    "        cleaned_war_artifacts.loc[start:end-1, column + '_Translated'] = translated_texts\n",
    "        time.sleep(1)  # Respect rate limits\n",
    "\n",
    "\n",
    "\n",
    "# Save the translated DataFrame to a new file\n",
    "# translated_df.to_csv('/path/to/your/translated_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat386",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
